
先说结论：**相似类型**的网络结构**影响不大**，**不同类型**的网络结构**影响较大**。全连接层（MLP）和卷积（CNN）、注意力机制（Tansformer）属于不同类型的网络结构，自然相差很大，它们用于不同的输入状态类型。

对于用**图像**作为状态输入，你只能用**CNN或Transformer**来抽取特征，从而使actor网络和critic网络训练地较好，全连接层几乎不能处理图像输入，除非是简单图像。

对于**用仿真器底部拿到的测量数据**作为状态输入，用**MLP**足矣，这种情况你反而不能用CNN和Transformer。

对于**用时间序列相关的数据**作为状态输入，那你可能需要**LSTM**网络。

我自己在做机器人强化学习实验的时候，发现如果用MLP不能收敛，用DenseNet同样也不能收敛，采用密集连接的DenseNet和MLP具有相似的结构，虽然DenseNet表征能力会稍强点，但是不收敛的问题不在于网络结构。

当然，以上讨论的前提是你的网络足够拟合这个问题，如果你用单隐层的MLP不收敛，用三隐层的MLP收敛了，这是因为单隐层MLP的表征能力太弱，不足以拟合这个问题。

