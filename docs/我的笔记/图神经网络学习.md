[4-用户行为图结构创建_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1ze4y1E7Xg?p=18&spm_id_from=pageDriver&vd_source=d31a858cc26ae1ffa19e14058b339f40)

图神经网络的任务形式：
- 针对图范围的任务：一个dataset有很多图，判断每个图的属性。比如一个分子式代表一张图，判断一个分子式的类别，那么每个图对应一个输出结果
- 针对节点范围的任务：一个dataset只有一个图，判断每个节点的属性。比如社交网络是一个图，每个节点表示一个人，那么每个节点对应一个输出结果

### 1.图神经网络的库

pytorch geometric
[Installation — pytorch_geometric documentation (pytorch-geometric.readthedocs.io)](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html)
一个使用demo（节点分类）

```python
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

from torch_geometric.datasets import Planetoid

dataset = Planetoid(root='/tmp/Cora', name='Cora')

class GCN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(dataset.num_node_features, 16)
        self.conv2 = GCNConv(16, dataset.num_classes)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)

        return F.log_softmax(x, dim=1)
        
#train
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GCN().to(device)
data = dataset[0].to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

model.train()
for epoch in range(200):
    optimizer.zero_grad()
    out = model(data)
    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])#只计算有标签的节点
    loss.backward()
    optimizer.step()
```

```python
model.eval()
pred = model(data).argmax(dim=1)
correct = (pred[data.test_mask]  data.y[data.test_mask]).sum()
acc = int(correct) / int(data.test_mask.sum())
print(f'Accuracy: {acc:.4f}')
>>> Accuracy: 0.8150
```

数据集的制作：
```python
import torch
from torch_geometric.data import Data

edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)

data = Data(x=x, edge_index=edge_index)#一般给出数据的邻接矩阵，也可以给出y（标签）

>>> Data(edge_index=[2, 4], x=[3, 1])
```
![[Pasted image 20230603195803.png]]


[1-构建数据集基本方法_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1ze4y1E7Xg?p=15&vd_source=d31a858cc26ae1ffa19e14058b339f40)


![[Pasted image 20230603203021.png]]



![[Pasted image 20230603203925.png]]
![[Pasted image 20230603203907.png]]

一个Date代表一个图，然后合成一个dataset

![[Pasted image 20230603204756.png]]
![[Pasted image 20230603204833.png]]

### 2.图神经网络的教程

[9. 3-邻接的矩阵的变换_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1HA411Q7AJ?p=12&spm_id_from=pageDriver&vd_source=d31a858cc26ae1ffa19e14058b339f40)

- 图神经网络的适用任务：输入数据不规则，比如化学分子式、社交网络等。一般CV或者NLP的输入数据都很规则，因此不用GNN
- 图神经网络的流程：
	- 给出特征矩阵X、度矩阵D、邻接矩阵A
	- 







![[Pasted image 20230603195230.png]]

![[Pasted image 20230603195333.png]]

度矩阵也加上自身（也就是对角值都加上1）
![[Pasted image 20230603195907.png]]

![[Pasted image 20230603200014.png]]

右乘对列做归一化
![[Pasted image 20230603200127.png]]


![[Pasted image 20230603200354.png]]

![[Pasted image 20230603200609.png]]

做了两层，有两个参数矩阵w0和w1
![[Pasted image 20230603200846.png]]


GCN一般不需要层数太多，层数越多感受野越大，一般3-5层效果最好
![[Pasted image 20230603201012.png]]


### 3. 图神经网络的attention

 图神经网络的attention其实就是对邻接矩阵进行参数化，实现小数的邻接矩阵（邻接矩阵的重构）
![[Pasted image 20230603210807.png]]